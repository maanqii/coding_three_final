{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+XLDy4uc0ogoMdpRxpW2I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maanqii/coding_three_final/blob/main/coding_three_change2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Notes provided by chatgpt"
      ],
      "metadata": {
        "id": "480SG4_fjEKQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgThnGT67wOC"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Import what we need\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "import scipy.misc\n",
        "import tensorflow as tf  # Import TensorFlow after Scipy or Scipy will break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "# Constants for the image input and output.\n",
        "###############################################################################\n",
        "\n",
        "# Output folder for the images.\n",
        "OUTPUT_DIR = 'output/'\n",
        "# Style image to use.\n",
        "STYLE_IMAGE = 'images/guernica.jpg'\n",
        "# Content image to use.\n",
        "CONTENT_IMAGE = 'images/hongkong.jpg'\n",
        "# Image dimensions constants.\n",
        "IMAGE_WIDTH = 800\n",
        "IMAGE_HEIGHT = 600\n",
        "COLOR_CHANNELS = 3"
      ],
      "metadata": {
        "id": "EzgszBEs8P--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "# Algorithm constants\n",
        "###############################################################################\n",
        "# Noise ratio. Percentage of weight of the noise for intermixing with the\n",
        "# content image.\n",
        "NOISE_RATIO = 0.6\n",
        "# Constant to put more emphasis on content loss.\n",
        "BETA = 5\n",
        "# Constant to put more emphasis on style loss.\n",
        "ALPHA = 100\n",
        "# Path to the deep learning model. This is more than 500MB so will not be\n",
        "# included in the repository, but available to download at the model Zoo:\n",
        "# Link: https://github.com/BVLC/caffe/wiki/Model-Zoo\n",
        "#\n",
        "# Pick the VGG 19-layer model by from the paper \"Very Deep Convolutional\n",
        "# Networks for Large-Scale Image Recognition\".\n",
        "\n",
        "## Set the number of iterations\n",
        "ITERATIONS = 1000\n",
        "\n",
        "VGG_MODEL = 'imagenet-vgg-verydeep-19.mat'\n",
        "# The mean to subtract from the input to the VGG model. This is the mean that\n",
        "# when the VGG was used to train. Minor changes to this will make a lot of\n",
        "# difference to the performance of model.\n",
        "MEAN_VALUES = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))\n",
        "\n",
        "## Set the convolution layers to be used\n",
        "CONTENT_LAYERS = [('conv4_2', 1.)]\n",
        "STYLE_LAYERS = [('conv1_1', 0.2), ('conv2_1', 0.2), ('conv3_1', 0.2), ('conv4_1', 0.2), ('conv5_1', 0.2)]"
      ],
      "metadata": {
        "id": "0YmvZDFY8mwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##takes three parameters: ntype (type of the layer), nin (input to the layer), and nwb (weights and biases for the layer, optional).\n",
        "##It builds a layer based on the ntype and returns the output of the layer. It supports two types of layers: convolutional ('conv') and pooling ('pool').\n",
        "##For a convolutional layer, it applies the convolution operation with given strides and padding, and then applies the ReLU activation function.\n",
        "def build_net(ntype, nin, nwb=None):\n",
        "    if ntype == 'conv':\n",
        "        return tf.nn.relu(tf.nn.conv2d(nin, nwb[0], strides=[1, 1, 1, 1], padding='SAME') + nwb[1])\n",
        "    elif ntype == 'pool':\n",
        "        return tf.nn.avg_pool(nin, ksize=[1, 2, 2, 1],\n",
        "                              strides=[1, 2, 2, 1], padding='SAME')\n",
        "\n",
        "\n",
        "def get_weight_bias(vgg_layers, i):\n",
        "    weights = vgg_layers[i][0][0][2][0][0]\n",
        "    weights = tf.constant(weights)\n",
        "    bias = vgg_layers[i][0][0][2][0][1]\n",
        "    bias = tf.constant(np.reshape(bias, (bias.size)))\n",
        "    return weights, bias\n",
        "\n",
        "\n",
        "def build_vgg19(path):\n",
        "    net = {}\n",
        "    vgg_rawnet = scipy.io.loadmat(path)\n",
        "    vgg_layers = vgg_rawnet['layers'][0]\n",
        "    net['input'] = tf.Variable(np.zeros((1, IMAGE_HEIGHT, IMAGE_WIDTH, 3)).astype('float32'))\n",
        "    net['conv1_1'] = build_net('conv', net['input'], get_weight_bias(vgg_layers, 0))\n",
        "    net['conv1_2'] = build_net('conv', net['conv1_1'], get_weight_bias(vgg_layers, 2))\n",
        "    net['pool1'] = build_net('pool', net['conv1_2'])\n",
        "    net['conv2_1'] = build_net('conv', net['pool1'], get_weight_bias(vgg_layers, 5))\n",
        "    net['conv2_2'] = build_net('conv', net['conv2_1'], get_weight_bias(vgg_layers, 7))\n",
        "    net['pool2'] = build_net('pool', net['conv2_2'])\n",
        "    net['conv3_1'] = build_net('conv', net['pool2'], get_weight_bias(vgg_layers, 10))\n",
        "    net['conv3_2'] = build_net('conv', net['conv3_1'], get_weight_bias(vgg_layers, 12))\n",
        "    net['conv3_3'] = build_net('conv', net['conv3_2'], get_weight_bias(vgg_layers, 14))\n",
        "    net['conv3_4'] = build_net('conv', net['conv3_3'], get_weight_bias(vgg_layers, 16))\n",
        "    net['pool3'] = build_net('pool', net['conv3_4'])\n",
        "    net['conv4_1'] = build_net('conv', net['pool3'], get_weight_bias(vgg_layers, 19))\n",
        "    net['conv4_2'] = build_net('conv', net['conv4_1'], get_weight_bias(vgg_layers, 21))\n",
        "    net['conv4_3'] = build_net('conv', net['conv4_2'], get_weight_bias(vgg_layers, 23))\n",
        "    net['conv4_4'] = build_net('conv', net['conv4_3'], get_weight_bias(vgg_layers, 25))\n",
        "    net['pool4'] = build_net('pool', net['conv4_4'])\n",
        "    net['conv5_1'] = build_net('conv', net['pool4'], get_weight_bias(vgg_layers, 28))\n",
        "    net['conv5_2'] = build_net('conv', net['conv5_1'], get_weight_bias(vgg_layers, 30))\n",
        "    net['conv5_3'] = build_net('conv', net['conv5_2'], get_weight_bias(vgg_layers, 32))\n",
        "    net['conv5_4'] = build_net('conv', net['conv5_3'], get_weight_bias(vgg_layers, 34))\n",
        "    net['pool5'] = build_net('pool', net['conv5_4'])\n",
        "    return net"
      ],
      "metadata": {
        "id": "OXv4VOFG-baV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_noise_image(content_image, noise_ratio = NOISE_RATIO):\n",
        "    \"\"\"\n",
        "    Returns a noise image intermixed with the content image at a certain ratio.\n",
        "    \"\"\"\n",
        "    noise_image = np.random.uniform(\n",
        "            -20, 20,\n",
        "            (1, IMAGE_HEIGHT, IMAGE_WIDTH, COLOR_CHANNELS)).astype('float32')\n",
        "    # White noise image from the content representation. Take a weighted average\n",
        "    # of the values\n",
        "    input_image = noise_image * noise_ratio + content_image * (1 - noise_ratio)\n",
        "    return input_image\n",
        "\n",
        "def load_image(path):\n",
        "    image = scipy.misc.imread(path)\n",
        "    # Resize the image for convnet input, there is no change but just\n",
        "    # add an extra dimension.\n",
        "    image = np.reshape(image, ((1,) + image.shape))\n",
        "    # Input to the VGG model expects the mean to be subtracted.\n",
        "    image = image - MEAN_VALUES\n",
        "    return image\n",
        "\n",
        "def save_image(path, image):\n",
        "    # Output should add back the mean.\n",
        "    image = image + MEAN_VALUES\n",
        "    # Get rid of the first useless dimension, what remains is the image.\n",
        "    image = image[0]\n",
        "    image = np.clip(image, 0, 255).astype('uint8')\n",
        "    scipy.misc.imsave(path, image)"
      ],
      "metadata": {
        "id": "PWdCwcEI9YLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##content_layer_loss(p, x): This function calculates the content loss between the feature representations of the content image (p) and the generated image (x). It computes the mean squared error (MSE) between x and p and scales it by a factor of 1 / (2 * N * M), where N represents the number of channels and M represents the spatial dimensions of the feature maps. The computed loss is returned.\n",
        "\n",
        "##content_loss_func(sess, net): This function computes the total content loss for the generated image given the feature representations of the content image. It iterates over the specified CONTENT_LAYERS and calculates the content loss for each layer. The content representation p is obtained by running the corresponding layer in the network (net[layer_name]) using the TensorFlow session sess. The generated image representation x is already stored in net[layer_name]. The content loss for each layer is multiplied by its respective weight and accumulated to compute the total content loss. The final content loss is divided by the number of layers to obtain an average loss and returned.\n",
        "\n",
        "##gram_matrix(x, area, depth): This function computes the Gram matrix of the feature maps x. It reshapes x into a 2D tensor of shape (area, depth), where area represents the spatial area (width * height) of the feature maps, and depth represents the number of channels. The Gram matrix is computed by taking the dot product of the reshaped x with its transpose. The resulting Gram matrix is returned.\n",
        "\n",
        "##style_layer_loss(a, x): This function calculates the style loss between the Gram matrix of the style image (a) and the generated image (x). It computes the mean squared error (MSE) between x and a Gram matrices, scaled by a factor of 1 / (4 * N^2 * M^2), where N represents the number of channels and M represents the spatial dimensions of the feature maps. The computed loss is returned.\n",
        "\n",
        "##style_loss_func(sess, net): This function computes the total style loss for the generated image given the Gram matrices of the style image. It iterates over the specified STYLE_LAYERS and calculates the style loss for each layer. The style representation a is obtained by running the corresponding layer in the network (net[layer_name]) using the TensorFlow session sess. The generated image representation x is already stored in net[layer_name]. The style loss for each layer is multiplied by its respective weight and accumulated to compute the total style loss. The final style loss is divided by the number of layers to obtain an average loss and returned.\n",
        "\n",
        "def content_layer_loss(p, x):\n",
        "\n",
        "    M = p.shape[1] * p.shape[2]\n",
        "    N = p.shape[3]\n",
        "    loss = (1. / (2 * N * M)) * tf.reduce_sum(tf.pow((x - p), 2))\n",
        "    return loss\n",
        "\n",
        "\n",
        "def content_loss_func(sess, net):\n",
        "\n",
        "    layers = CONTENT_LAYERS\n",
        "    total_content_loss = 0.0\n",
        "    for layer_name, weight in layers:\n",
        "        p = sess.run(net[layer_name])\n",
        "        x = net[layer_name]\n",
        "        total_content_loss += content_layer_loss(p, x)*weight\n",
        "\n",
        "    total_content_loss /= float(len(layers))\n",
        "    return total_content_loss\n",
        "\n",
        "\n",
        "def gram_matrix(x, area, depth):\n",
        "\n",
        "    x1 = tf.reshape(x, (area, depth))\n",
        "    g = tf.matmul(tf.transpose(x1), x1)\n",
        "    return g\n",
        "\n",
        "def style_layer_loss(a, x):\n",
        "\n",
        "    M = a.shape[1] * a.shape[2]\n",
        "    N = a.shape[3]\n",
        "    A = gram_matrix(a, M, N)\n",
        "    G = gram_matrix(x, M, N)\n",
        "    loss = (1. / (4 * N ** 2 * M ** 2)) * tf.reduce_sum(tf.pow((G - A), 2))\n",
        "    return loss\n",
        "\n",
        "\n",
        "def style_loss_func(sess, net):\n",
        "\n",
        "    layers = STYLE_LAYERS\n",
        "    total_style_loss = 0.0\n",
        "    for layer_name, weight in layers:\n",
        "        a = sess.run(net[layer_name])\n",
        "        x = net[layer_name]\n",
        "        total_style_loss += style_layer_loss(a, x) * weight\n",
        "    total_style_loss /= float(len(layers))\n",
        "    return total_style_loss"
      ],
      "metadata": {
        "id": "ZXyjs11Z9jBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##net = build_vgg19(VGG_Model): The VGG19 network is built by calling the build_vgg19 function, which returns a dictionary containing the layers of the network. The VGG model path (VGG_Model) is provided as an argument.\n",
        "\n",
        "##sess = tf.Session(): A TensorFlow session is created.\n",
        "\n",
        "##sess.run(tf.initialize_all_variables()): The variables in the session are initialized.\n",
        "\n",
        "##content_img = load_image(CONTENT_IMAGE): The content image is loaded using the load_image function. The content image path (CONTENT_IMAGE) is provided as an argument.\n",
        "\n",
        "##style_img = load_image(STYLE_IMAGE): The style image is loaded using the load_image function. The style image path (STYLE_IMAGE) is provided as an argument.\n",
        "\n",
        "##s##ess.run([net['input'].assign(content_img)]): The content image is assigned to the input variable of the network.\n",
        "\n",
        "##cost_content = content_loss_func(sess, net): The content loss is calculated using the content_loss_func function.\n",
        "\n",
        "##sess.run([net['input'].assign(style_img)]): The style image is assigned to the input variable of the network.\n",
        "\n",
        "##cost_style = style_loss_func(sess, net): The style loss is calculated using the style_loss_func function.\n",
        "\n",
        "##total_loss = alpha * cost_content + beta * cost_style: The total loss is computed as a weighted sum of the content loss (cost_content) and style loss (cost_style), where alpha and beta are weighting factors.\n",
        "\n",
        "##optimizer = tf.train.AdamOptimizer(2.0): An Adam optimizer is created with a learning rate of 2.0.\n",
        "\n",
        "##init_img = generate_noise_image(content_img): An initial image for optimization is generated by adding random noise to the content image using the generate_noise_image function.\n",
        "\n",
        "##train_op = optimizer.minimize(total_loss): The optimization operation is defined using the Adam optimizer to minimize the total loss.\n",
        "\n",
        "##sess.run(tf.initialize_all_variables()): The variables in the session are reinitialized.\n",
        "\n",
        "##sess.run(net['input'].assign(init_img)): The initial image is assigned to the input variable of the network.\n",
        "\n",
        "##The following code runs the training loop for a specified number of iterations (ITERATIONS):\n",
        "\n",
        "sess.run(train_op): The optimization operation is executed to update the image towards minimizing the total loss.\n",
        "The loss and current image information is printed every 100 iterations.\n",
        "The current image is saved to the output directory using the save_image function.\n",
        "def main():\n",
        "    net = build_vgg19(VGG_Model)\n",
        "    sess = tf.Session()\n",
        "    sess.run(tf.initialize_all_variables())\n",
        "\n",
        "    content_img = load_image(CONTENT_IMAGE)\n",
        "    style_img = load_image(STYLE_IMAGE)\n",
        "\n",
        "    sess.run([net['input'].assign(content_img)])\n",
        "    cost_content = content_loss_func(sess, net)\n",
        "\n",
        "    sess.run([net['input'].assign(style_img)])\n",
        "    cost_style = style_loss_func(sess, net)\n",
        "\n",
        "    total_loss = alpha * cost_content + beta * cost_style\n",
        "    optimizer = tf.train.AdamOptimizer(2.0)\n",
        "\n",
        "    init_img = generate_noise_image(content_img)\n",
        "\n",
        "    train_op = optimizer.minimize(total_loss)\n",
        "    sess.run(tf.initialize_all_variables())\n",
        "    sess.run(net['input'].assign(init_img))\n",
        "\n",
        "    for it in range(ITERATIONS):\n",
        "        sess.run(train_op)\n",
        "        if it % 100 == 0:\n",
        "            # Print every 100 iteration.\n",
        "            mixed_image = sess.run(net['input'])\n",
        "            print('Iteration %d' % (it))\n",
        "            print('sum : ', sess.run(tf.reduce_sum(mixed_image)))\n",
        "            print('cost: ', sess.run(total_loss))\n",
        "\n",
        "            if not os.path.exists(OUTPUT_DIR):\n",
        "                os.mkdir(OUTPUT_DIR)\n",
        "\n",
        "            filename = 'output/%d.png' % (it)\n",
        "            save_image(filename, mixed_image)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "55xOrqo4-yhN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}